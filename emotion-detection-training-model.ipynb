{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:59:31.741325Z","iopub.status.busy":"2024-04-23T04:59:31.741047Z","iopub.status.idle":"2024-04-23T04:59:44.847381Z","shell.execute_reply":"2024-04-23T04:59:44.846485Z","shell.execute_reply.started":"2024-04-23T04:59:31.741301Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import PIL\n","import io\n","import seaborn as sns\n","import pandas as pd\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import matplotlib.image as mpimg\n","\n","from keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report\n","\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:21:55.270492Z","iopub.status.busy":"2024-04-23T06:21:55.269618Z","iopub.status.idle":"2024-04-23T06:21:55.274687Z","shell.execute_reply":"2024-04-23T06:21:55.273579Z","shell.execute_reply.started":"2024-04-23T06:21:55.270463Z"},"trusted":true},"outputs":[],"source":["picture_size = 48\n","main_path = \"/kaggle/input/emotion-dataset/images/train\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:21:57.147128Z","iopub.status.busy":"2024-04-23T06:21:57.146466Z","iopub.status.idle":"2024-04-23T06:21:57.176942Z","shell.execute_reply":"2024-04-23T06:21:57.176186Z","shell.execute_reply.started":"2024-04-23T06:21:57.147099Z"},"trusted":true},"outputs":[],"source":["import os\n","emotion_categories = os.listdir(main_path)\n","emotion_categories"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:22:03.479033Z","iopub.status.busy":"2024-04-23T06:22:03.478659Z","iopub.status.idle":"2024-04-23T06:22:03.484350Z","shell.execute_reply":"2024-04-23T06:22:03.483392Z","shell.execute_reply.started":"2024-04-23T06:22:03.479003Z"},"trusted":true},"outputs":[],"source":["# for categories paths\n","for subfolder in emotion_categories:\n","    category_path = os.path.join(main_path,subfolder)\n","    print(category_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:22:04.199956Z","iopub.status.busy":"2024-04-23T06:22:04.199286Z","iopub.status.idle":"2024-04-23T06:22:10.136964Z","shell.execute_reply":"2024-04-23T06:22:10.136093Z","shell.execute_reply.started":"2024-04-23T06:22:04.199930Z"},"trusted":true},"outputs":[],"source":["# Define the number of images to display from each category\n","num_images_per_category = 4\n","\n","# Calculate total number of subplots needed\n","total_subplots = len(emotion_categories) * num_images_per_category\n","\n","# Set up the figure and subplots\n","fig = plt.figure(figsize=(12, 12))\n","\n","# Loop through each emotion category\n","for i, category in enumerate(emotion_categories):\n","    # Define the path to the specific emotion category folder\n","    category_folder = os.path.join(main_path, category)\n","    \n","    # Get the list of categories paths in the category folder\n","    image_files = os.listdir(category_folder)\n","    \n","    # Display a maximum of num_images_per_category images from this category\n","    for j in range(min(num_images_per_category, len(image_files))):\n","        # Construct the full path to the image file\n","        image_path = os.path.join(category_folder, image_files[j])\n","        \n","        # Load the image in grayscale\n","        image = mpimg.imread(image_path)\n","        \n","        # Create subplot\n","        ax = plt.subplot(len(emotion_categories), num_images_per_category, i * num_images_per_category + j + 1)\n","        \n","        # Display the grayscale image\n","        ax.imshow(image, cmap='gray')\n","        ax.set_title(category)\n","        ax.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:22:25.482782Z","iopub.status.busy":"2024-04-23T06:22:25.482415Z","iopub.status.idle":"2024-04-23T06:22:25.487322Z","shell.execute_reply":"2024-04-23T06:22:25.486272Z","shell.execute_reply.started":"2024-04-23T06:22:25.482755Z"},"trusted":true},"outputs":[],"source":["TRAIN_DIR = \"/kaggle/input/emotion-dataset//images/train\"\n","TEST_DIR = \"/kaggle/input/emotion-dataset//images/validation\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:22:26.805252Z","iopub.status.busy":"2024-04-23T06:22:26.804421Z","iopub.status.idle":"2024-04-23T06:22:26.809887Z","shell.execute_reply":"2024-04-23T06:22:26.808880Z","shell.execute_reply.started":"2024-04-23T06:22:26.805219Z"},"trusted":true},"outputs":[],"source":["from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:22:27.868591Z","iopub.status.busy":"2024-04-23T06:22:27.867883Z","iopub.status.idle":"2024-04-23T06:22:27.874675Z","shell.execute_reply":"2024-04-23T06:22:27.873564Z","shell.execute_reply.started":"2024-04-23T06:22:27.868563Z"},"trusted":true},"outputs":[],"source":["def createdataframe(dir):\n","    image_paths = []\n","    labels = []\n","\n","    try:\n","        for label in os.listdir(dir):\n","            for imagename in os.listdir(os.path.join(dir, label)):\n","                image_paths.append(os.path.join(dir, label, imagename))\n","                labels.append(label)\n","            print(label, \"completed\")\n","    except FileNotFoundError:\n","        print(f\"Directory not found: {dir}\")\n","\n","    return image_paths, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:22:29.105322Z","iopub.status.busy":"2024-04-23T06:22:29.104959Z","iopub.status.idle":"2024-04-23T06:22:29.205127Z","shell.execute_reply":"2024-04-23T06:22:29.204129Z","shell.execute_reply.started":"2024-04-23T06:22:29.105294Z"},"trusted":true},"outputs":[],"source":["train = pd.DataFrame()\n","train['image'], train['label'] = createdataframe(TRAIN_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:22:30.705626Z","iopub.status.busy":"2024-04-23T06:22:30.704764Z","iopub.status.idle":"2024-04-23T06:22:33.385406Z","shell.execute_reply":"2024-04-23T06:22:33.384382Z","shell.execute_reply.started":"2024-04-23T06:22:30.705593Z"},"trusted":true},"outputs":[],"source":["test = pd.DataFrame()\n","test['image'], test['label'] = createdataframe(TEST_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:22:33.387230Z","iopub.status.busy":"2024-04-23T06:22:33.386929Z","iopub.status.idle":"2024-04-23T06:22:33.393225Z","shell.execute_reply":"2024-04-23T06:22:33.392206Z","shell.execute_reply.started":"2024-04-23T06:22:33.387205Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","def extract_features(images):\n","    features = []\n","    for image in tqdm(images):\n","        img = Image.open(image).convert('L')  # Load image in grayscale\n","        img = np.array(img)\n","        features.append(img)\n","    features = np.array(features)\n","    features = features.reshape(len(features), 48, 48, 1)\n","    return features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:22:33.394774Z","iopub.status.busy":"2024-04-23T06:22:33.394448Z","iopub.status.idle":"2024-04-23T06:26:23.932567Z","shell.execute_reply":"2024-04-23T06:26:23.931490Z","shell.execute_reply.started":"2024-04-23T06:22:33.394749Z"},"trusted":true},"outputs":[],"source":["train_features = extract_features(train['image']) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:26:23.935009Z","iopub.status.busy":"2024-04-23T06:26:23.934712Z","iopub.status.idle":"2024-04-23T06:27:07.587043Z","shell.execute_reply":"2024-04-23T06:27:07.586279Z","shell.execute_reply.started":"2024-04-23T06:26:23.934984Z"},"trusted":true},"outputs":[],"source":["test_features = extract_features(test['image'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:27:50.037870Z","iopub.status.busy":"2024-04-23T06:27:50.037009Z","iopub.status.idle":"2024-04-23T06:27:50.241866Z","shell.execute_reply":"2024-04-23T06:27:50.240936Z","shell.execute_reply.started":"2024-04-23T06:27:50.037839Z"},"trusted":true},"outputs":[],"source":["x_train = train_features/255.0\n","x_test = test_features/255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:27:51.624250Z","iopub.status.busy":"2024-04-23T06:27:51.623882Z","iopub.status.idle":"2024-04-23T06:27:51.628871Z","shell.execute_reply":"2024-04-23T06:27:51.627930Z","shell.execute_reply.started":"2024-04-23T06:27:51.624223Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:27:52.515435Z","iopub.status.busy":"2024-04-23T06:27:52.515087Z","iopub.status.idle":"2024-04-23T06:27:52.525661Z","shell.execute_reply":"2024-04-23T06:27:52.524661Z","shell.execute_reply.started":"2024-04-23T06:27:52.515410Z"},"trusted":true},"outputs":[],"source":["le = LabelEncoder()\n","le.fit(train['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:27:53.142189Z","iopub.status.busy":"2024-04-23T06:27:53.141834Z","iopub.status.idle":"2024-04-23T06:27:53.154241Z","shell.execute_reply":"2024-04-23T06:27:53.153353Z","shell.execute_reply.started":"2024-04-23T06:27:53.142161Z"},"trusted":true},"outputs":[],"source":["y_train = le.transform(train['label'])\n","y_test = le.transform(test['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:28:01.834088Z","iopub.status.busy":"2024-04-23T06:28:01.833723Z","iopub.status.idle":"2024-04-23T06:28:01.840351Z","shell.execute_reply":"2024-04-23T06:28:01.839335Z","shell.execute_reply.started":"2024-04-23T06:28:01.834060Z"},"trusted":true},"outputs":[],"source":["y_train = to_categorical(y_train,num_classes = 7)\n","y_test = to_categorical(y_test,num_classes = 7)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:28:03.047619Z","iopub.status.busy":"2024-04-23T06:28:03.046985Z","iopub.status.idle":"2024-04-23T06:28:03.343920Z","shell.execute_reply":"2024-04-23T06:28:03.342982Z","shell.execute_reply.started":"2024-04-23T06:28:03.047582Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Create an ImageDataGenerator instance with augmentation parameters\n","datagen = ImageDataGenerator(\n","    rotation_range=20,      # Random rotation up to 20 degrees\n","    width_shift_range=0.2,  # Random horizontal shift\n","    height_shift_range=0.2, # Random vertical shift\n","    shear_range=0.2,        # Shear intensity\n","    zoom_range=0.2,         # Random zoom\n","    horizontal_flip=True,   # Random horizontal flip\n","    fill_mode='nearest'     # Fill mode for pixels outside the boundaries\n",")\n","\n","# Example usage with a batch of images\n","# Assume x_train is your training data with shape (num_samples, height, width, channels)\n","# and y_train is your corresponding labels\n","datagen.fit(x_train)\n","\n","# Create a generator that yields augmented batches of data\n","augmented_generator = datagen.flow(x_train, y_train, batch_size=128)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:28:05.390459Z","iopub.status.busy":"2024-04-23T06:28:05.389791Z","iopub.status.idle":"2024-04-23T06:28:05.395745Z","shell.execute_reply":"2024-04-23T06:28:05.394813Z","shell.execute_reply.started":"2024-04-23T06:28:05.390425Z"},"trusted":true},"outputs":[],"source":["# Callbacks\n","\n","early_stopping = EarlyStopping(\n","    monitor='val_accuracy',\n","    min_delta=0.00005,\n","    patience=7,\n","    verbose=1,\n","    restore_best_weights=True,\n",")\n","\n","lr_scheduler = ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.3,\n","    patience=7,\n","    min_lr=1e-6,\n","    verbose=1,\n",")\n","\n","callbacks = [\n","    early_stopping,\n","    lr_scheduler,\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:29:10.739804Z","iopub.status.busy":"2024-04-23T06:29:10.739101Z","iopub.status.idle":"2024-04-23T06:29:11.019917Z","shell.execute_reply":"2024-04-23T06:29:11.019015Z","shell.execute_reply.started":"2024-04-23T06:29:10.739774Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","import tensorflow as tf\n","\n","# Create the Sequential model\n","model = Sequential()\n","\n","# Module 1\n","model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(48, 48 , 1), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.3))\n","\n","# Module 2\n","model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.3))\n","\n","# Module 3\n","model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.3))\n","\n","# Flatten\n","model.add(Flatten())\n","\n","# Dense layers\n","model.add(Dense(128))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","# Output layer\n","model.add(Dense(4, activation='softmax'))\n","\n","\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(learning_rate=0.001),\n","              metrics=['accuracy'])\n","# Display the model summary\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:29:12.007853Z","iopub.status.busy":"2024-04-23T06:29:12.007111Z","iopub.status.idle":"2024-04-23T06:53:57.958494Z","shell.execute_reply":"2024-04-23T06:53:57.957681Z","shell.execute_reply.started":"2024-04-23T06:29:12.007821Z"},"trusted":true},"outputs":[],"source":["history  = model.fit(augmented_generator, steps_per_epoch=int(len(x_train) / 128), epochs=200, validation_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T06:16:08.884281Z","iopub.status.busy":"2024-04-23T06:16:08.883296Z","iopub.status.idle":"2024-04-23T06:16:08.952297Z","shell.execute_reply":"2024-04-23T06:16:08.951314Z","shell.execute_reply.started":"2024-04-23T06:16:08.884247Z"},"trusted":true},"outputs":[],"source":["model_json = model.to_json()\n","with open(\"emotiondetector.json\",'w') as json_file:\n","    json_file.write(model_json)\n","model.save(\"emotiondetector.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T14:46:35.521674Z","iopub.status.busy":"2024-04-16T14:46:35.520912Z","iopub.status.idle":"2024-04-16T14:46:35.801461Z","shell.execute_reply":"2024-04-16T14:46:35.800615Z","shell.execute_reply.started":"2024-04-16T14:46:35.521641Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import model_from_json\n","\n","json_file = open(\"/kaggle/working/emotiondetector.json\", \"r\")\n","model_json = json_file.read()\n","json_file.close()\n","model = model_from_json(model_json)\n","model.load_weights(\"/kaggle/working/emotiondetector.h5\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T14:50:38.596543Z","iopub.status.busy":"2024-04-16T14:50:38.595638Z","iopub.status.idle":"2024-04-16T14:50:39.422406Z","shell.execute_reply":"2024-04-16T14:50:39.421294Z","shell.execute_reply.started":"2024-04-16T14:50:38.596507Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","# Assuming you have your test data and labels ready\n","# x_test and y_true are the test data and true labels respectively\n","\n","# Make predictions using the loaded model\n","y_pred_probabilities = model.predict(x_test)\n","y_pred = np.argmax(y_pred_probabilities, axis=1)\n","\n","y_test = np.argmax(y_test, axis=1)\n","\n","# Calculate the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n","plt.xlabel(\"Predicted labels\")\n","plt.ylabel(\"True labels\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T14:52:52.456824Z","iopub.status.busy":"2024-04-16T14:52:52.455893Z","iopub.status.idle":"2024-04-16T14:52:52.499337Z","shell.execute_reply":"2024-04-16T14:52:52.497986Z","shell.execute_reply.started":"2024-04-16T14:52:52.456775Z"},"trusted":true},"outputs":[],"source":["# Plot training & validation accuracy values\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":99505,"sourceId":234911,"sourceType":"datasetVersion"},{"datasetId":4794168,"sourceId":8114902,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
